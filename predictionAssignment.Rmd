---
title: "ML assignment"
author: "Raphael Villedieu"
date: "October 24, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

Load test and training sets with appropriate NA strings

```{r}
library(caret)
trainingSet <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!",""))
testingSet <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""))
```

Remove index and IDs because they are irrelevant

```{r}
training <- trainingSet[c(-1,-2)]
testing <- testingSet[c(-1,-2)]
```
Exclude near zero variance features

```{r}
nzvcol <- nearZeroVar(training)
training <- training[, -nzvcol]
```

```{r}
for (i in 1:length(testing) ) {
        for(j in 1:length(training)) {
        if(  names(testing[i]) == names( training[j]) )  {
            class(training[[j]]) <- class(testing[[i]])
        }      
    }      
}

```
The whole training set is used for training. However we are going to use cross-validation for evaluating our model.
Create 10 training and testing set from the training set.

```{r}
trainingFolds <- createFolds(training[,1], k = 10, list = TRUE, returnTrain = TRUE)
```

Train a decision tree with rpart on the whole training set

```{r}
library(rpart)
modfit <- rpart(classe ~ ., data=training, method="class")
```

Plot the relative error:
```{r}
printcp(modfit)
```
```{r}
predictions <- predict(modfit, training, type = "class")
```

The accuracy is:

```{r}
confusionMatrix(predictions, training$classe)$overall[[1]]
```

Now repeat training and evaluating using the 10-folds:

```{r}
accuracy <- vector(length = 10)
for(i in 1:10){
  # Get i-th fold and build training and testing sets
  XTrain = training[ trainingFolds[[i]] , ]
  XTest = training[ - trainingFolds[[i]] , ]
  # Train model with decision trees
  Xmodfit <- rpart(classe ~ ., data=XTrain, method="class")
  # Predict using current model for unseen data (XTest)
  predictions <- predict(Xmodfit, XTest, type = "class")
  accuracy[i] <- confusionMatrix(predictions, XTest$classe)$overall[[1]]
}  
```

The accuracies for the 10 models on unseen data are:

```{r}
accuracy
```

The mean is:

```{r}
mean(accuracy)
```

Now we can use the model we train on the whole training set in order to predict the class of the test set.
The predictions are:
```{r}
predict(modfit, testing, type = "class")
```




